{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0dd2e29-bbba-4f73-bdc7-74e625ef71d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123456)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bcc6cfc-c357-41e7-9653-de74807886b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入本文档所需的库\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27870d93-68e5-4127-bff1-b302541cbfba",
   "metadata": {},
   "source": [
    "### 1. 先查看目录中的图片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd5fc7-6b85-4ceb-a9a7-e5d23c461f6e",
   "metadata": {},
   "source": [
    "请根据[02-torchvison.datasets-保存图片到文件中.ipynb](./02-torchvison.datasets-保存图片到文件中.ipynb)准备好图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2508ae01-8bd1-4921-8800-a306878daaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     100\n"
     ]
    }
   ],
   "source": [
    "# 查看我们的目标目录中是否有图片\n",
    "!ls ../../data/images/CIFAR10/**/*.png | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be0960c-b5bc-48eb-837f-c19c42810e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../../data/images/CIFAR10/\u001b[0m\n",
      "├── \u001b[01;34mairplane\u001b[0m\n",
      "├── \u001b[01;34mautomobile\u001b[0m\n",
      "├── \u001b[01;34mbird\u001b[0m\n",
      "├── \u001b[01;34mcat\u001b[0m\n",
      "├── \u001b[01;34mdeer\u001b[0m\n",
      "├── \u001b[01;34mdog\u001b[0m\n",
      "├── \u001b[01;34mfrog\u001b[0m\n",
      "├── \u001b[01;34mhorse\u001b[0m\n",
      "├── \u001b[01;34mship\u001b[0m\n",
      "└── \u001b[01;34mtruck\u001b[0m\n",
      "\n",
      "11 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "# 查看图片目录\n",
    "!tree ../../data/images/CIFAR10/ -L 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e0472-f023-4d11-b78a-d9d1c47c611d",
   "metadata": {},
   "source": [
    "### 2. 使用ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610cd9e3-49b7-4750-b8ca-3d026548c0a8",
   "metadata": {},
   "source": [
    "### 2.1 实例化数据转换实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ff00c7-7403-40e7-a609-de6248df8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((16, 16)),  # 调整图片图像尺寸，其实可以不需要，但是为了练习加上\n",
    "    transforms.ToTensor(), # 将PIL图片转换为Tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 对图片张量归一化\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f28d3e-1eb5-4f43-8e2a-f5a144501b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(16, 16), interpolation=bilinear, max_size=None, antialias=True)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf60f6-64e1-4bc5-8dae-810c3721cc7d",
   "metadata": {},
   "source": [
    "### 2.2 加载图片数据\n",
    "\n",
    "如果`ImageFoler`不传递`transform`那么默认就是None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ba7046-9457-4fec-afa0-4abadfbb320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"../../data/images/CIFAR10\"\n",
    "images = datasets.ImageFolder(root=images_dir, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aacd999-4339-4b71-9566-c2fb11da3a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 100\n",
       "    Root location: ../../data/images/CIFAR10\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(16, 16), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef88542c-7816-45b1-978c-3e23bbfb0a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.folder.ImageFolder"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e19d82a1-8e19-4c66-a826-18bdf6cacfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cd167be-6bfa-482f-adde-5f41c58c10bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b042611-9da8-4921-a062-3464fd9e6752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, int)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到的数据是一个图像张量和一个标签\n",
    "type(images[0][0]), type(images[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d8d3f05-016b-43f5-8896-2e90a3d9ba55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[99][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ab5ad-ed3e-4ddc-a39c-23f3c4d97e41",
   "metadata": {},
   "source": [
    "**看一下不传递`transform`**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1de7fc8d-50df-4d3d-9461-b2498f39e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "images2 = datasets.ImageFolder(root=images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09903aae-71c8-4b19-91c5-f01ec9ace25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.folder.ImageFolder"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5257efd-6535-44fd-b4cd-c73bd64cab8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cc0f605-e19c-4a0c-ad6a-de22379666c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PIL.Image.Image, int)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images2[0][0]), type(images2[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ad60c13-4f92-4f6d-937b-e0a02822cf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=32x32 at 0x17536DED0>\n"
     ]
    }
   ],
   "source": [
    "print(images2[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736affd0-31a5-41fc-a595-8ccc42931367",
   "metadata": {},
   "source": [
    "### 2.3 使用DataLoader\n",
    "\n",
    "为了进行批处理和数据加载的并行化，通常会使用`DataLoader`。    \n",
    "常用的参数：\n",
    "- `dataset`: 必填，数据集实例\n",
    "- `batch_size`: 每个批次的样本数量， 默认是1\n",
    "- `shuffle`: `True`表示每次迭代前都打乱数据顺序\n",
    "- `num_workers`: 默认`0`(数据将在主进程中加载), 使用多少个子进程来并发加载数据\n",
    "- `collate_fn`: 一个可选的函数，用于将赝本列表转换为小批量。默认情况下，它会堆叠张量\n",
    "- `pin_memory`: 如果使用GPU，是否将张量复制到`CUDA`的固定内存中以加速数据传输，默认`False`\n",
    "- `drop_last`: 如果数据集大小不能被`batch_size`整除，是否丢弃最后一个不完整的批次，默认是`False`\n",
    "- `timeout`: 数据加载超时时间，单位为秒，防止加载数据的时候卡死，默认是`0`（无超时）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "928e9136-b500-4ac7-8df5-9b70c6d6892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "data_loader = DataLoader(images, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a82cb484-278a-42e3-860c-3ad3da7ec103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0afaa-a748-4244-9346-725702cbc495",
   "metadata": {},
   "source": [
    "`DataLoader`实例化的时候`batch_size=10`,那么当for执行的时候，会执行`len(datasets) / batch_size`次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a79befb-5faf-44b8-ac29-acc5262c9167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dbece6e-7514-435b-801f-a1dba2bc4465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1, i = 1, count=1\tlabels:tensor([6, 2, 1, 0, 3, 9, 1, 2, 0, 2])\n",
      "epoch=1, i = 2, count=2\tlabels:tensor([3, 7, 4, 1, 5, 9, 8, 4, 2, 5])\n",
      "epoch=1, i = 3, count=3\tlabels:tensor([7, 2, 2, 2, 9, 4, 7, 6, 1, 0])\n",
      "epoch=1, i = 4, count=4\tlabels:tensor([3, 5, 4, 4, 2, 6, 4, 3, 0, 1])\n",
      "epoch=1, i = 5, count=5\tlabels:tensor([1, 5, 2, 7, 3, 3, 7, 1, 3, 7])\n",
      "epoch=1, i = 6, count=6\tlabels:tensor([3, 1, 1, 3, 2, 1, 0, 4, 1, 9])\n",
      "epoch=1, i = 7, count=7\tlabels:tensor([3, 9, 7, 8, 9, 7, 5, 9, 0, 1])\n",
      "epoch=1, i = 8, count=8\tlabels:tensor([5, 7, 7, 1, 6, 3, 2, 8, 4, 4])\n",
      "epoch=1, i = 9, count=9\tlabels:tensor([9, 9, 4, 6, 3, 5, 9, 2, 6, 7])\n",
      "epoch=1, i = 10, count=10\tlabels:tensor([3, 8, 6, 4, 2, 9, 1, 9, 1, 1])\n",
      "\n",
      "epoch=2, i = 1, count=11\tlabels:tensor([7, 6, 2, 6, 1, 2, 9, 9, 2, 4])\n",
      "epoch=2, i = 2, count=12\tlabels:tensor([5, 7, 3, 3, 3, 1, 3, 4, 6, 7])\n",
      "epoch=2, i = 3, count=13\tlabels:tensor([1, 5, 1, 1, 7, 7, 3, 9, 9, 6])\n",
      "epoch=2, i = 4, count=14\tlabels:tensor([8, 7, 3, 0, 0, 0, 3, 4, 7, 9])\n",
      "epoch=2, i = 5, count=15\tlabels:tensor([6, 4, 8, 1, 5, 3, 3, 4, 4, 2])\n",
      "epoch=2, i = 6, count=16\tlabels:tensor([4, 4, 2, 7, 1, 1, 8, 6, 4, 1])\n",
      "epoch=2, i = 7, count=17\tlabels:tensor([0, 1, 3, 9, 5, 7, 9, 5, 9, 6])\n",
      "epoch=2, i = 8, count=18\tlabels:tensor([1, 4, 7, 9, 9, 2, 1, 5, 2, 5])\n",
      "epoch=2, i = 9, count=19\tlabels:tensor([1, 9, 8, 0, 1, 2, 2, 1, 9, 0])\n",
      "epoch=2, i = 10, count=20\tlabels:tensor([3, 2, 3, 1, 3, 2, 2, 2, 7, 4])\n",
      "\n",
      "count = 20\n"
     ]
    }
   ],
   "source": [
    "# 现在我们取2次图片数据\n",
    "count = 0\n",
    "for epoch in range(1, 3):\n",
    "    i = 0\n",
    "    for imgs, labels in data_loader:\n",
    "        i += 1\n",
    "        count += 1\n",
    "        print(f\"epoch={epoch}, i = {i}, count={count}\\tlabels:{labels}\")\n",
    "    print(\"\")\n",
    "print(f\"count = {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b585f-a6bf-424b-af4d-ca9e985e9b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36275cfc-0872-4255-8040-ca16b904fcdd",
   "metadata": {},
   "source": [
    "## 文本分类数据集：emotion\n",
    "\n",
    "在练习文本分类时我们第一步是需要先有相关文本的数据。这个数据集一般需要有2列：\n",
    "- 第一列就是文本(一句话)\n",
    "- 第二列是这句话是正面情绪还是负面情绪，可以用数字`0`、`1`来标识。也可以是多种情绪的比如：愤怒、厌恶、恐惧、喜悦、悲伤、惊讶等。\n",
    "  > HuggingFace中的`emotion`数据集就是有：anger、disgust、fear、joy、sadness和surprise。6中情绪的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe25522d-ab99-44e9-9fa9-5111dc83d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad4eda-e2ab-4657-aca9-3a54f77ffae0",
   "metadata": {},
   "source": [
    "### 1. 加载HuggingFace中的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f05b2d-b90f-492b-86d1-e59bfc52e92c",
   "metadata": {},
   "source": [
    "#### 1.1 使用load_dataset加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a342927d-47d6-4754-a2cb-6ae06197a747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/alex.zhou/.cache/huggingface/modules/datasets_modules/datasets/emotion/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd (last modified on Fri May 31 14:39:28 2024) since it couldn't be found locally at emotion, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一次加载的话去线上下载数据\n",
    "# 后续会使用本地的缓存，一般是：/Users/$Home/.cache/huggingface/modules/datasets_modules/datasets/emotion\n",
    "ds = datasets.load_dataset(\"emotion\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9a790d-1f12-46f7-ac64-ce4bff68fb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['train', 'validation', 'test']), datasets.dataset_dict.DatasetDict)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据集的键、查看数据集的类型\n",
    "ds.keys(), type(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d15e1b-5408-4ce9-b0f0-1ce6b45a0055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 16000\n",
      "})\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"train\"])\n",
    "print(type(ds[\"test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfbceb-bcc5-49f9-9965-f32fe21b7737",
   "metadata": {},
   "source": [
    "> `DatasetDict`对象类似于Python的字段，每个键对应不同的数据集(Dataset)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb3175-19ab-4dfb-8a3d-f4e8fa004b7b",
   "metadata": {},
   "source": [
    "#### 1.2 数据集基本操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c624f1-efa9-45fe-8ca2-2ebcb73f0a20",
   "metadata": {},
   "source": [
    "**查看数据集的某类数据集(根据key获取):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883a985e-f505-4bb8-bae0-030fee4c486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 16000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练数据集\n",
    "train_ds = ds[\"train\"]\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad92a9e6-1d85-417e-a190-03cc278d69d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据集的长度\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9a15eb3-32fa-4e4e-ac13-5ab4c05dec2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据集的类型\n",
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12268d17-cc68-482c-b5d9-c0797147c42b",
   "metadata": {},
   "source": [
    "**查看数据中的列/key:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14e003d9-d874-411c-a5bd-eb1501df3e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'label']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57f6432-b459-4f11-8204-8b265670f66f",
   "metadata": {},
   "source": [
    "我们可以通过`Dataset`对象的`features`属性类查看背后使用了哪些数据类型。\n",
    "> datasets库是使用了`Apache Arrow`构建的，`Apache Arrow`定义了一种类型化的列格式。比原生的Python更有效的利用内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77656723-de14-4c6e-8b98-405ae896d669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5834cdc-394f-4356-8250-256088489dc6",
   "metadata": {},
   "source": [
    "**访问数据：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d19d5f21-8127-4c5d-bbf9-55f6786a3ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c69a216f-bc32-404b-9b33-e049034bc7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake'],\n",
       " 'label': [0, 0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3739cf4b-de50-4a9b-abcb-b0ca36d22dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datasets.arrow_dataset.Dataset,\n",
       " datasets.arrow_dataset.DatasetInfoMixin,\n",
       " datasets.search.IndexableMixin,\n",
       " datasets.arrow_dataset.TensorflowDatasetMixin,\n",
       " object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__class__.__mro__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23870715-a593-420c-a61c-d2f66b1ba30a",
   "metadata": {},
   "source": [
    "#### 1.3 数据集DatasetDict格式转换\n",
    "\n",
    "> 我们可以通过`DatasetDict`对象的`set_format()`方法，更改数据集的输出格式进行转换，且随时可以切换另外一种格式。   \n",
    "> 可选的格式有：`[None, 'numpy', 'torch', 'tensorflow', 'pandas', 'arrow', 'jax']`。\n",
    "> \n",
    "> 如果想恢复数据了，那么使用`DatasetDict`对象的`reset_format()`方法即可。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43715f31-375f-4f3d-be93-e4e8f1b2c7ba",
   "metadata": {},
   "source": [
    "##### 1. 把数据转换为pandas的DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e790bcfb-277b-42b9-82ad-678afbf12372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i didnt feel humiliated', 'label': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换之前我们先看一下里面数据的格式\n",
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0a15f62-fba9-4538-a39f-7e83998a8a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8675e641-66ef-4804-9b66-257079c931b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format(type=\"pandas\")\n",
    "# 没传递columns，那么默认就是全部的列\n",
    "# ds.set_format(type=\"pandas\", columns=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e4ebe3-1385-4c52-bba0-840d333bfed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      text  label\n",
       "0  i didnt feel humiliated      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0a5c2a8-e3ff-48b6-bf60-6a4376448cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看类型\n",
    "type(ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec17bd-5f73-407c-88aa-fdbc4aefb9c5",
   "metadata": {},
   "source": [
    "> 可以看到我们在对数据集设置type之前，里面的数据是`dict`类型，设置之后就变成`DataFrame`了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "034ff4a5-5e06-4508-80c4-a5b7d08e8111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们在前面有执行：train_ds = ds[\"train\"]\n",
    "train_ds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637d69d-84a9-41b7-ab7b-1b88795ab97c",
   "metadata": {},
   "source": [
    "> 可以发现，`set_format()`方法，并不会改变底层的数据格式（Arrow）表，我们可以通过`reset_format`方法恢复默认格式，或者重新切换到另外一种格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35899ef-d2d2-4cd4-958c-54232fd54911",
   "metadata": {},
   "source": [
    "##### 2. 切换为PyTorch的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132e67b-4440-460e-af0b-4fe73e541b07",
   "metadata": {},
   "source": [
    "> 前面我们把数据格式设置为了`pandas`，现在我们把它们设置为`torch`（PyTorch的张量）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7186f67-ffbe-469b-80ad-d2a617fb7ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fbdc9bf-e8f7-435f-8b2f-d2e21050640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f6ba6f6-b479-4ebe-885b-c882fcf37912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'im grabbing a minute to post i feel greedy wrong',\n",
       "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
       "  'i am feeling grouchy'],\n",
       " 'label': tensor([0, 0, 3, 2, 3])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再次查看训练数据集的第一个数据\n",
    "ds[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c11b4ae6-918d-4f86-b27a-e5d8d408b825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds[\"train\"][0][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd6512e-f00c-4ac2-bed8-59288370e97e",
   "metadata": {},
   "source": [
    "##### 3. 重置数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b753485e-d04a-40a1-afb2-daec4360a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f9f640-80c4-4f6f-9898-af47b200fdda",
   "metadata": {},
   "source": [
    "#### 1.4 给数据集添加列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e28132d-4fa6-4b19-8162-ff4286a531d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa9fa57-b9d8-4523-9808-9ce121c99e9e",
   "metadata": {},
   "source": [
    "我们再次把数据格式转换为`pandas`后，再来添加列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b1c8720-3d60-4f97-8953-288fc518eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "893983e1-e4c3-4569-ab1a-4bf185112190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df1c434a-4f80-43d9-9c85-ae663004235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 16000\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b4d9277-22e2-4420-9380-74521c3bc9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ea7dfd7-e2a7-413b-8281-85f3baaae0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.features[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0acd853-b23a-4767-b340-312226cf3b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.features.features.ClassLabel"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds.features[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07b7c933-ff9e-46f6-94ec-3fd4e9857968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ClassLabel有个`int2str`的方法可以把数值转换为字符\n",
    "train_ds.features[\"label\"].int2str(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59d9b69f-8c91-411b-a2ae-0e28e61dd67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataframe = train_ds[:]\n",
    "train_df = train_ds[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb66287f-33be-4854-abce-17581834720d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5b1ded-9a05-450c-b646-ac3e6c8e7c00",
   "metadata": {},
   "source": [
    "现在我们利用ClassLabel的`int2str`方法给数据添加一个列`label_name`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd30416d-985b-46f5-903b-5dbdb91b0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label_name\"] = train_df[\"label\"].apply(lambda l: train_ds.features[\"label\"].int2str(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5ad27e2-2833-4202-bec8-29796d5e1f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name\n",
       "0                            i didnt feel humiliated      0    sadness\n",
       "1  i can go from feeling so hopeless to so damned...      0    sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong      3      anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      2       love\n",
       "4                               i am feeling grouchy      3      anger"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e027908-54d3-4fbd-a9ca-e0121881fb66",
   "metadata": {},
   "source": [
    "**现在我们加好了一列了**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e71bbd3f-1564-42f9-9e39-5ebc0a503522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label', 'label_name'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7234800-679e-476a-9a58-579d607080e2",
   "metadata": {},
   "source": [
    "### 2. 给数据集的文本分词和获取嵌入向量\n",
    "\n",
    "> 我们使用预训练的模型`bert-base-uncased`给文本分词和获取嵌入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2994a4ce-c239-4a65-bf99-780f200e7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cac6d32-b8ab-4d3b-aba3-730b0de443ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f20ad928-07d3-43f4-a15f-d54737b445e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先给数据恢复为默认格式\n",
    "ds.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04243087-3999-4cbd-b3c3-01c88452dad2",
   "metadata": {},
   "source": [
    "### 2.1 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "412328ce-03fa-46f8-b802-8781d3a33a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name\n",
       "0                            i didnt feel humiliated      0    sadness\n",
       "1  i can go from feeling so hopeless to so damned...      0    sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong      3      anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      2       love\n",
       "4                               i am feeling grouchy      3      anger"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68256762-b406-42d5-bdd5-ddd0d8cc4b9b",
   "metadata": {},
   "source": [
    "先实例化分词器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24e8fae5-8f5c-4dfc-afef-3d5befa60a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f1f0e95-ad05-43bd-89bf-a2b0d484b09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'python', 'and', 'transforms', '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"I love python and transforms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad6eb34f-1d25-46ff-a128-a10f0a6ce338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'didn', '##t', 'feel', 'humiliated']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(train_df[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "656f502e-e3c5-4311-bd1f-c2f77d25a56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_df[\"text\"][0], max_length=15, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "748675ff-5c0a-449f-ba6d-e176e1b4210f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'i',\n",
       " 'didn',\n",
       " '##t',\n",
       " 'feel',\n",
       " 'humiliated',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8867ca-db50-4c8b-88ac-b151c7edb8e0",
   "metadata": {},
   "source": [
    "**现在我们给其添加tokens的列**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d78d52e-94af-48b6-aaac-1456fc40370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"tokens\"] = train_df[\"text\"].apply(lambda x: tokenizer.convert_ids_to_tokens(tokenizer(x).input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0f774f4-756e-4e88-83dc-7c3e9cf65bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[[CLS], i, didn, ##t, feel, humiliated, [SEP]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[[CLS], i, can, go, from, feeling, so, hopeles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>[[CLS], im, grabbing, a, minute, to, post, i, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "      <td>[[CLS], i, am, ever, feeling, nos, ##tal, ##gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>[[CLS], i, am, feeling, gr, ##ou, ##chy, [SEP]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name  \\\n",
       "0                            i didnt feel humiliated      0    sadness   \n",
       "1  i can go from feeling so hopeless to so damned...      0    sadness   \n",
       "2   im grabbing a minute to post i feel greedy wrong      3      anger   \n",
       "3  i am ever feeling nostalgic about the fireplac...      2       love   \n",
       "4                               i am feeling grouchy      3      anger   \n",
       "\n",
       "                                              tokens  \n",
       "0     [[CLS], i, didn, ##t, feel, humiliated, [SEP]]  \n",
       "1  [[CLS], i, can, go, from, feeling, so, hopeles...  \n",
       "2  [[CLS], im, grabbing, a, minute, to, post, i, ...  \n",
       "3  [[CLS], i, am, ever, feeling, nos, ##tal, ##gi...  \n",
       "4    [[CLS], i, am, feeling, gr, ##ou, ##chy, [SEP]]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e26f4c-8ba5-4eb0-9d72-c0dfd2f176bd",
   "metadata": {},
   "source": [
    "`tokenizer()`方法会返回有`input_ids`、`token_type_ids`、和`attention_mask`字段，我们想把这几个字段加入到`train_df`中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e1f6e0-fd7c-47dc-9c38-2f4b9eb9140c",
   "metadata": {},
   "source": [
    "#### 2.2 直接给数据集加上tokenizer返回的字段"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004b1b0-4917-4523-a099-b4a1c735ea84",
   "metadata": {},
   "source": [
    "`datasets.dataset_dict.DatasetDict`对象的`map()`方法，默认是按单个样本操作的，我们可以设置其为一批一批的操作(`batch=True`)即可。`batch_size=None`会把整个数据集作为一个批量应用map的函数。    \n",
    "还可以设置多线程来处理数据：`num_proc=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52fdb94a-4450-43eb-888e-bf815d1bd39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_handler(batch):\n",
    "    # padding = True 是零填充样本，如果设置max_length=N, padding=\"max_length\"，那么会填充[PAD]到末尾\n",
    "    # truncation = True 是将样本截断为模型的最大上下文大小\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "affd5045-f21e-4064-a333-2eefe86a79f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d0849845d54f10ae14d0b1ad7de2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=3):   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2963fbb32d414ce5a65314be7c0ee447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=3):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5371499f6424867834d3885f6f3e5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=3):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# map方法会把input_ids、token_type_ids、和attention_mask字段直接添加到数据集中\n",
    "ds_encode = ds.map(tokenize_handler, batched=True, batch_size=1000, num_proc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73bb3497-0295-4d17-81e5-6cb1b3bd95f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59915265-ada5-4d2c-becf-a3416a42a9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c842f-fc4f-46d5-b498-53a95b52a9f6",
   "metadata": {},
   "source": [
    "执行完`map()`后，我们可以看到`tokenizer`返回的3个数据列(`input_ids`、`token_type_ids`、`attention_mask`)添加到了数据集中了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "855426f0-3839-4030-9308-799802654ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c2085b0-2e83-49b6-88d5-1a802f8c165a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['text', 'label'],\n",
       " ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"].column_names, ds_encode[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d336d5e-1ac5-4928-b8e5-b2ffdcb68c21",
   "metadata": {},
   "source": [
    "#### 2.3 获取嵌入向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "986d213b-2b9a-40ac-905c-ea7fd41248e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84af43b7-9c58-416e-8c61-dee2548f3b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看模型编码器的层数\n",
    "len(model.encoder.layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb27230-3ce5-4118-bf15-86e1c2e40ca1",
   "metadata": {},
   "source": [
    "**第一步：**  先获取一个句子的特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17fe6169-66a9-4824-9c36-f67d274e69e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2293, 18750,  1998, 10938,  2121,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_inputs = tokenizer([\"I love python and transformer.\"], return_tensors=\"pt\")\n",
    "token_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d638923-324d-4c55-93d2-b7231e25c109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**token_inputs)\n",
    "type(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82559400-988f-47c0-93c4-726559e68067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ce5ff70-0de0-4019-9004-a84912f406cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state, pooler_output = outputs['last_hidden_state'], outputs['pooler_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62e15332-d955-4c41-9bf2-b73e76d4b6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38609701-9ccd-43dc-90f5-f3d618a49105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', 'love', 'python', 'and', 'transform', '##er', '.', '[SEP]']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(token_inputs[\"input_ids\"][0])\n",
    "print(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21604494-4067-427c-bc7d-9e4f04545190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a9863-8f3a-4b92-abc1-8172da10dac2",
   "metadata": {},
   "source": [
    "`last_hidden_state`最后一层隐藏状态为`[batch_size, n_tokens, hidden_dim]`。     \n",
    "我们有一个句子`I love python and transformer.`这里`tokens`的长度是9(`['[CLS]', 'i', 'love', 'python', 'and', 'transform', '##er', '.', '[SEP]']`)。\n",
    "\n",
    "`768`是模型隐藏状态的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "089bdeba-0ccf-48e8-a3fa-e50241f4c986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [CLS]就是代表整个句子的特征值: 在文本分类，对整个句子的情感分析，用的就是这个特征向量\n",
    "last_hidden_state[0, 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d3766-ce73-4cf5-97f4-2f8b0f30bcda",
   "metadata": {},
   "source": [
    "**第二步：** 批量获取数据的特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba4cf0ab-f99d-4479-957f-bca15167e562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "35f971cb-4e8f-498d-9cb2-fababb796a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置ds的格式为torch\n",
    "ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0509991-df3a-4783-9972-8fbee9802d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_hidden_states(batch, device=\"cpu\"):\n",
    "    # 先判断是否可以使用GPU\n",
    "    # device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    # 通过text直接分词\n",
    "    inputs = tokenizer(batch[\"text\"], truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # inputs = {\n",
    "    #     k: v.to(device) for k, v in batch.items()\n",
    "    #     if k in tokenizer.model_input_names\n",
    "    # }\n",
    "            \n",
    "        \n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            last_hidden_state = model(**inputs).last_hidden_state\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(inputs)\n",
    "            print(batch, batch[\"text\"])\n",
    "            return {}\n",
    "\n",
    "    # 返回\n",
    "    # return {\"hidden_state\": last_hidden_state[:,0].numpy()}\n",
    "    return {\"hidden_state\": last_hidden_state[:,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16d7a4ef-1a91-4b83-a99f-cb296c4591ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a81d24acf84f88b8c94e99663b9ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0106237e7e4f8283aa3b35e467c373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c2475adedb4d00b14e477522d878d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 31s, sys: 9min 36s, total: 30min 8s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "# 继续使用ds的map方法, 默认batch_size是1000\n",
    "%time ds_embeddings = ds.map(get_text_hidden_states, batched=True, batch_size=500)\n",
    "\n",
    "# ds_encode.set_format(\"torch\")\n",
    "# %time ds_embeddings = ds_encode.map(get_text_hidden_states2, batched=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5af6cdde-382e-491b-802a-4c933510905d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bdc09d4e-7212-4991-8114-1c6ae727e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time ds_embeddings = ds.map(get_text_hidden_states, batched=True)\n",
    "# GPU获取嵌入向量，待优化，会报错。取batch数据的时候，Tensor2维的数据变成了一个Tensor的列表了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2202a-34b9-4b70-9d2b-e20aa36c22cd",
   "metadata": {},
   "source": [
    "> CPU times: user 19min 22s, sys: 8min 39s, total: 28min 2s    \n",
    "Wall time: 3min 34s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df67046f-4731-4fe4-a250-cd0082e33e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'hidden_state'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'hidden_state'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'hidden_state'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1fffb539-781a-4ef6-96b8-a44a9114ba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_embeddings[\"train\"][0][\"hidden_state\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7180fa-c409-4881-b5ca-801bb439bee8",
   "metadata": {},
   "source": [
    "**现在就可以利用`hidden_state`进行文本分类了**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec92250d-adaa-4fa0-8e25-79dec1f104c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

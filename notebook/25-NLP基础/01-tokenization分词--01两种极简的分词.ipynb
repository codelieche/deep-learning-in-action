{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d530a3-49b5-4090-8166-6037538f7d6e",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ab9a4-c21b-4c01-88af-e16d8e2aa0db",
   "metadata": {},
   "source": [
    "NLP中三个重要的部分：分词(`tokenization`)、向量嵌入(`enbedding`)、网络架构(`architecture`)。    \n",
    "- 分词器、向量嵌入、模型都可以看做是一个独立的函数。这些函数接收一些输入，并生成一些输出。   \n",
    "- 每个函数都会将输出传递到下一个流水线中的环节。     \n",
    "- 我们把分词后的文本传递到向量嵌入层，向量嵌入层再传递到模型中。   \n",
    "- 在学习过程中，我们可以将这些函数视为黑盒，并且一次只关注其中的一个环节。\n",
    "\n",
    "分词器是一个将字符串序列转换为词条(`Token`)序列的程序。\n",
    "\n",
    "**分词器是模型用来读取文本，向量嵌入是模型用来理解文本的。**\n",
    "\n",
    "`tokenization`: 分词/词元化是指将字符串分解为给模型使用的`token`(原子单元)的步骤。   \n",
    "词元化测策略有很多种，我们具体使用那种方案最佳，通常都需要从语料库中学习。\n",
    "\n",
    "接下来我们讨论一下两种极端的分词器：\n",
    "- 字符词元化\n",
    "- 单词词元化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e321866f-b3dd-46d5-b647-27f746affdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9cb36-0e3c-46d7-ae51-20661583546d",
   "metadata": {},
   "source": [
    "### 1. 字符词元化\n",
    "\n",
    "> 把字符串按照字符级别拆分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec391a6-a634-4c13-a867-a659c6f1b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备一段文本\n",
    "text = \"\"\"\n",
    "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\n",
    "\n",
    "Features described in this documentation are classified by release status:\n",
    "\n",
    "Stable: These features will be maintained long-term and there should generally be no major performance limitations or gaps in documentation. We also expect to maintain backwards compatibility (although breaking changes can happen and notice will be given one release ahead of time).\n",
    "\n",
    "Beta: These features are tagged as Beta because the API may change based on user feedback, because the performance needs to improve, or because coverage across operators is not yet complete. For Beta features, we are committing to seeing the feature through to the Stable classification. We are not, however, committing to backwards compatibility.\n",
    "\n",
    "Prototype: These features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6617ff6-f383-4963-844b-b168fc0c2245",
   "metadata": {},
   "source": [
    "先把换行符替换为空格："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbd08a0-b1bf-4393-a8c7-dfdeeefb4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4901a6de-98ad-4303-934c-bc1b2b0ee311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.  Features described in this documentation are classified by release status:  Stable: These features will be maintained long-term and there should generally be no major performance limitations or gaps in documentation. We also expect to maintain backwards compatibility (although breaking changes can happen and notice will be given one release ahead of time).  Beta: These features are tagged as Beta because the API may change based on user feedback, because the performance needs to improve, or because coverage across operators is not yet complete. For Beta features, we are committing to seeing the feature through to the Stable classification. We are not, however, committing to backwards compatibility.  Prototype: These features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing. '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed67fdc-a21a-466c-949f-a3a812564bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "987"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接使用list把字符串拆分为单个的字符列表\n",
    "tokenized_text_list = list(text)\n",
    "len(tokenized_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b212de-7dd6-4824-8347-98f0c52fb864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "987"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29f6182-dab9-4509-a255-3d7ae33b1a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在计算出所有字符的集合，并排好序\n",
    "tokenized_tokens_set = sorted(set(tokenized_text_list))\n",
    "len(tokenized_tokens_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e0103-6b4d-4b4c-b6e6-271273c36e93",
   "metadata": {},
   "source": [
    "> 我们的语料库中字符总共有43个。我们把其从第一个到最后一个分别用数字1,2,....,42编好号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb7ca3c-70ee-4f9b-9fc3-cc2de88e617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '(', ')', ',', '-', '.', ':', 'A', 'B', 'C', 'F', 'G', 'I', 'P', 'S', 'T', 'U', 'W', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_tokens_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "034cb541-35a1-457e-934b-9d2efa75766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '(': 1, ')': 2, ',': 3, '-': 4, '.': 5, ':': 6, 'A': 7, 'B': 8, 'C': 9, 'F': 10, 'G': 11, 'I': 12, 'P': 13, 'S': 14, 'T': 15, 'U': 16, 'W': 17, 'a': 18, 'b': 19, 'c': 20, 'd': 21, 'e': 22, 'f': 23, 'g': 24, 'h': 25, 'i': 26, 'j': 27, 'k': 28, 'l': 29, 'm': 30, 'n': 31, 'o': 32, 'p': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'w': 39, 'x': 40, 'y': 41, 'z': 42}\n",
      "\n",
      "词表的长度： 43\n"
     ]
    }
   ],
   "source": [
    "# token到数字的映射\n",
    "token2index = {\n",
    "    c: index\n",
    "    for index, c in enumerate(tokenized_tokens_set)\n",
    "}\n",
    "print(token2index)\n",
    "print(\"\\n词表的长度：\", len(token2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb588e9-6746-4bc8-bdbd-8936aa427f52",
   "metadata": {},
   "source": [
    "> 我们得到了一个包含每个字符到唯一整数的映射，即分词器的此表。其词表的长度是43。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a9540-a6f3-4639-b96a-1eb0a88768e9",
   "metadata": {},
   "source": [
    "**现在我们有了词表，有了分词的文本列表，可把字符文本列表转换为一个整数列表了。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55292da5-ca3f-4dfa-ba80-cae0dc2d5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [token2index.get(token, 0) for token in tokenized_text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b7a3c41-8b6d-43b6-98b3-e31b015ef4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 13, 41, 15, 32, 34, 20, 25, 0, 26, 35, 0, 18, 31, 0, 32, 33, 36, 26, 30, 26, 42, 22, 21, 0, 36, 22, 31, 35, 32, 34, 0, 29, 26, 19, 34, 18, 34, 41, 0, 23, 32, 34, 0, 21, 22, 22, 33, 0, 29, 22, 18, 34, 31, 26, 31, 24, 0, 37, 35, 26, 31, 24, 0, 11, 13, 16, 35, 0, 18, 31, 21, 0, 9, 13, 16, 35, 5, 0, 0, 10, 22, 18, 36, 37, 34, 22, 35, 0, 21, 22, 35, 20, 34, 26, 19, 22, 21, 0, 26, 31, 0, 36, 25, 26, 35, 0, 21, 32, 20, 37, 30, 22, 31, 36, 18, 36, 26, 32, 31, 0, 18, 34, 22, 0, 20, 29, 18, 35, 35, 26, 23, 26, 22, 21, 0, 19, 41, 0, 34, 22, 29, 22, 18, 35, 22, 0, 35, 36, 18, 36, 37, 35, 6, 0, 0, 14, 36, 18, 19, 29, 22, 6, 0, 15, 25, 22, 35, 22, 0, 23, 22, 18, 36, 37, 34, 22, 35, 0, 39, 26, 29, 29, 0, 19, 22, 0, 30, 18, 26, 31, 36, 18, 26, 31, 22, 21, 0, 29, 32, 31, 24, 4, 36, 22, 34, 30, 0, 18, 31, 21, 0, 36, 25, 22, 34, 22, 0, 35, 25, 32, 37, 29, 21, 0, 24, 22, 31, 22, 34, 18, 29, 29, 41, 0, 19, 22, 0, 31, 32, 0, 30, 18, 27, 32, 34, 0, 33, 22, 34, 23, 32, 34, 30, 18, 31, 20, 22, 0, 29, 26, 30, 26, 36, 18, 36, 26, 32, 31, 35, 0, 32, 34, 0, 24, 18, 33, 35, 0, 26, 31, 0, 21, 32, 20, 37, 30, 22, 31, 36, 18, 36, 26, 32, 31, 5, 0, 17, 22, 0, 18, 29, 35, 32, 0, 22, 40, 33, 22, 20, 36, 0, 36, 32, 0, 30, 18, 26, 31, 36, 18, 26, 31, 0, 19, 18, 20, 28, 39, 18, 34, 21, 35, 0, 20, 32, 30, 33, 18, 36, 26, 19, 26, 29, 26, 36, 41, 0, 1, 18, 29, 36, 25, 32, 37, 24, 25, 0, 19, 34, 22, 18, 28, 26, 31, 24, 0, 20, 25, 18, 31, 24, 22, 35, 0, 20, 18, 31, 0, 25, 18, 33, 33, 22, 31, 0, 18, 31, 21, 0, 31, 32, 36, 26, 20, 22, 0, 39, 26, 29, 29, 0, 19, 22, 0, 24, 26, 38, 22, 31, 0, 32, 31, 22, 0, 34, 22, 29, 22, 18, 35, 22, 0, 18, 25, 22, 18, 21, 0, 32, 23, 0, 36, 26, 30, 22, 2, 5, 0, 0, 8, 22, 36, 18, 6, 0, 15, 25, 22, 35, 22, 0, 23, 22, 18, 36, 37, 34, 22, 35, 0, 18, 34, 22, 0, 36, 18, 24, 24, 22, 21, 0, 18, 35, 0, 8, 22, 36, 18, 0, 19, 22, 20, 18, 37, 35, 22, 0, 36, 25, 22, 0, 7, 13, 12, 0, 30, 18, 41, 0, 20, 25, 18, 31, 24, 22, 0, 19, 18, 35, 22, 21, 0, 32, 31, 0, 37, 35, 22, 34, 0, 23, 22, 22, 21, 19, 18, 20, 28, 3, 0, 19, 22, 20, 18, 37, 35, 22, 0, 36, 25, 22, 0, 33, 22, 34, 23, 32, 34, 30, 18, 31, 20, 22, 0, 31, 22, 22, 21, 35, 0, 36, 32, 0, 26, 30, 33, 34, 32, 38, 22, 3, 0, 32, 34, 0, 19, 22, 20, 18, 37, 35, 22, 0, 20, 32, 38, 22, 34, 18, 24, 22, 0, 18, 20, 34, 32, 35, 35, 0, 32, 33, 22, 34, 18, 36, 32, 34, 35, 0, 26, 35, 0, 31, 32, 36, 0, 41, 22, 36, 0, 20, 32, 30, 33, 29, 22, 36, 22, 5, 0, 10, 32, 34, 0, 8, 22, 36, 18, 0, 23, 22, 18, 36, 37, 34, 22, 35, 3, 0, 39, 22, 0, 18, 34, 22, 0, 20, 32, 30, 30, 26, 36, 36, 26, 31, 24, 0, 36, 32, 0, 35, 22, 22, 26, 31, 24, 0, 36, 25, 22, 0, 23, 22, 18, 36, 37, 34, 22, 0, 36, 25, 34, 32, 37, 24, 25, 0, 36, 32, 0, 36, 25, 22, 0, 14, 36, 18, 19, 29, 22, 0, 20, 29, 18, 35, 35, 26, 23, 26, 20, 18, 36, 26, 32, 31, 5, 0, 17, 22, 0, 18, 34, 22, 0, 31, 32, 36, 3, 0, 25, 32, 39, 22, 38, 22, 34, 3, 0, 20, 32, 30, 30, 26, 36, 36, 26, 31, 24, 0, 36, 32, 0, 19, 18, 20, 28, 39, 18, 34, 21, 35, 0, 20, 32, 30, 33, 18, 36, 26, 19, 26, 29, 26, 36, 41, 5, 0, 0, 13, 34, 32, 36, 32, 36, 41, 33, 22, 6, 0, 15, 25, 22, 35, 22, 0, 23, 22, 18, 36, 37, 34, 22, 35, 0, 18, 34, 22, 0, 36, 41, 33, 26, 20, 18, 29, 29, 41, 0, 31, 32, 36, 0, 18, 38, 18, 26, 29, 18, 19, 29, 22, 0, 18, 35, 0, 33, 18, 34, 36, 0, 32, 23, 0, 19, 26, 31, 18, 34, 41, 0, 21, 26, 35, 36, 34, 26, 19, 37, 36, 26, 32, 31, 35, 0, 29, 26, 28, 22, 0, 13, 41, 13, 12, 0, 32, 34, 0, 9, 32, 31, 21, 18, 3, 0, 22, 40, 20, 22, 33, 36, 0, 35, 32, 30, 22, 36, 26, 30, 22, 35, 0, 19, 22, 25, 26, 31, 21, 0, 34, 37, 31, 4, 36, 26, 30, 22, 0, 23, 29, 18, 24, 35, 3, 0, 18, 31, 21, 0, 18, 34, 22, 0, 18, 36, 0, 18, 31, 0, 22, 18, 34, 29, 41, 0, 35, 36, 18, 24, 22, 0, 23, 32, 34, 0, 23, 22, 22, 21, 19, 18, 20, 28, 0, 18, 31, 21, 0, 36, 22, 35, 36, 26, 31, 24, 5, 0]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf87b6-4654-4a58-96c7-2d57dc2b0b85",
   "metadata": {},
   "source": [
    "**接下来我们将这个整数的列表，转换为独热编码向量(one-hot)**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce7a924a-7138-4eff-ad4f-7b9994d9eaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([987, 43])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把整数列表，转换为张量\n",
    "input_ids_tensor = torch.tensor(input_ids)\n",
    "# 直接使用torch.nn.functional实例化one_hot\n",
    "input_ids_one_hot_encodings = F.one_hot(input_ids_tensor, num_classes=len(token2index))\n",
    "\n",
    "# 查看独热编码后的形状\n",
    "input_ids_one_hot_encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2480303b-529f-4e1a-9832-073f1b023576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一个token是：s(35)\n"
     ]
    }
   ],
   "source": [
    "# 查看第11个token\n",
    "print(\"第一个token是：{}({})\".format(tokenized_text_list[10], token2index[tokenized_text_list[10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73133bfa-bd40-4bb8-9bbe-b746ec31ec2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看第11个token的独热编码\n",
    "input_ids_one_hot_encodings[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fdd57c6-e68b-4496-9edb-7692c9bc903a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(35)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看第11个token的独热编码 最大值的index\n",
    "torch.argmax(input_ids_one_hot_encodings[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391f26fd-ea54-40ed-a32e-815dfea40fd7",
   "metadata": {},
   "source": [
    "### 2. 单词词元化\n",
    "> 把字符串按照单词级别拆分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830776ca-75c3-476b-a2bb-c8866df54783",
   "metadata": {},
   "source": [
    "把文本根据空格分割出所有的单词:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c35e23c-f989-4f8c-8230-a0d7c1e8dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split(\" \")\n",
    "# 去掉,.等\n",
    "words = [word.strip(')(,.;:!?_-\"') for word in words]\n",
    "# 排除空单词''\n",
    "words = [word for word in words if word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4010e1d7-c192-4266-962b-be51fa7ed012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PyTorch', 'is', 'an', 'optimized', 'tensor', 'library', 'for', 'deep', 'learning', 'using', 'GPUs', 'and', 'CPUs', 'Features', 'described', 'in', 'this', 'documentation', 'are', 'classified', 'by', 'release', 'status', 'Stable', 'These', 'features', 'will', 'be', 'maintained', 'long-term', 'and', 'there', 'should', 'generally', 'be', 'no', 'major', 'performance', 'limitations', 'or', 'gaps', 'in', 'documentation', 'We', 'also', 'expect', 'to', 'maintain', 'backwards', 'compatibility', 'although', 'breaking', 'changes', 'can', 'happen', 'and', 'notice', 'will', 'be', 'given', 'one', 'release', 'ahead', 'of', 'time', 'Beta', 'These', 'features', 'are', 'tagged', 'as', 'Beta', 'because', 'the', 'API', 'may', 'change', 'based', 'on', 'user', 'feedback', 'because', 'the', 'performance', 'needs', 'to', 'improve', 'or', 'because', 'coverage', 'across', 'operators', 'is', 'not', 'yet', 'complete', 'For', 'Beta', 'features', 'we', 'are', 'committing', 'to', 'seeing', 'the', 'feature', 'through', 'to', 'the', 'Stable', 'classification', 'We', 'are', 'not', 'however', 'committing', 'to', 'backwards', 'compatibility', 'Prototype', 'These', 'features', 'are', 'typically', 'not', 'available', 'as', 'part', 'of', 'binary', 'distributions', 'like', 'PyPI', 'or', 'Conda', 'except', 'sometimes', 'behind', 'run-time', 'flags', 'and', 'are', 'at', 'an', 'early', 'stage', 'for', 'feedback', 'and', 'testing']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f84fd-df4a-4198-b9cb-53b045dfc8cf",
   "metadata": {},
   "source": [
    "让单词变为唯一，且排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6c03af1-f542-44f0-854e-ed30dd2c75a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['API', 'Beta', 'CPUs', 'Conda', 'Features', 'For', 'GPUs', 'Prototype', 'PyPI', 'PyTorch', 'Stable', 'These', 'We', 'across', 'ahead', 'also', 'although', 'an', 'and', 'are', 'as', 'at', 'available', 'backwards', 'based', 'be', 'because', 'behind', 'binary', 'breaking', 'by', 'can', 'change', 'changes', 'classification', 'classified', 'committing', 'compatibility', 'complete', 'coverage', 'deep', 'described', 'distributions', 'documentation', 'early', 'except', 'expect', 'feature', 'features', 'feedback', 'flags', 'for', 'gaps', 'generally', 'given', 'happen', 'however', 'improve', 'in', 'is', 'learning', 'library', 'like', 'limitations', 'long-term', 'maintain', 'maintained', 'major', 'may', 'needs', 'no', 'not', 'notice', 'of', 'on', 'one', 'operators', 'optimized', 'or', 'part', 'performance', 'release', 'run-time', 'seeing', 'should', 'sometimes', 'stage', 'status', 'tagged', 'tensor', 'testing', 'the', 'there', 'this', 'through', 'time', 'to', 'typically', 'user', 'using', 'we', 'will', 'yet']\n"
     ]
    }
   ],
   "source": [
    "words_set = sorted(set(words))\n",
    "print(words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48d32118-aa49-40d0-b705-969426f09a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {\n",
    "    v: k for k, v in enumerate(words_set)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7277571d-7e6c-459e-a86d-6475f61833eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API : 0\n",
      "Beta : 1\n",
      "CPUs : 2\n",
      "Conda : 3\n",
      "Features : 4\n",
      "For : 5\n",
      "GPUs : 6\n",
      "Prototype : 7\n",
      "PyPI : 8\n",
      "PyTorch : 9\n",
      "Stable : 10\n"
     ]
    }
   ],
   "source": [
    "# 查看前面10个token\n",
    "i = 0\n",
    "for k, v in tokens.items():\n",
    "    print(k, \":\", v)\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "294e76d4-a4e6-4727-98d7-a6952d2a644a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf171209-c01c-42e8-ae8c-44b0f3abb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取单词的ids\n",
    "word_ids = [tokens.get(word, 0) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b797e01c-9634-4b49-aad4-1e149f24d0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 59, 17, 77, 89, 61, 51, 40, 60, 99, 6, 18, 2, 4, 41, 58, 93, 43, 19, 35, 30, 81, 87, 10, 11, 48, 101, 25, 66, 64, 18, 92, 84, 53, 25, 70, 67, 80, 63, 78, 52, 58, 43, 12, 15, 46, 96, 65, 23, 37, 16, 29, 33, 31, 55, 18, 72, 101, 25, 54, 75, 81, 14, 73, 95, 1, 11, 48, 19, 88, 20, 1, 26, 91, 0, 68, 32, 24, 74, 98, 49, 26, 91, 80, 69, 96, 57, 78, 26, 39, 13, 76, 59, 71, 102, 38, 5, 1, 48, 100, 19, 36, 96, 83, 91, 47, 94, 96, 91, 10, 34, 12, 19, 71, 56, 36, 96, 23, 37, 7, 11, 48, 19, 97, 71, 22, 20, 79, 73, 28, 42, 62, 8, 78, 3, 45, 85, 27, 82, 50, 18, 19, 21, 17, 44, 86, 51, 49, 18, 90]\n"
     ]
    }
   ],
   "source": [
    "print(word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c74169d9-019c-4296-ae68-9495e2ed2c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02dd3c1-86e6-4e8c-9012-b53ba9b1d709",
   "metadata": {},
   "source": [
    "**使用独热编码来展示word_ids**:\n",
    "\n",
    "`one-hot`向量数组中，一个元素是`1`，其它的元素都是`0`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79c36f5e-86ee-4b73-9fb7-b9c1205c1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ids_one_hot = torch.zeros(len(word_ids), len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05617ab3-94eb-453e-9cac-b5af02b24754",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, token in enumerate(word_ids):\n",
    "    # print(idx, token)\n",
    "    word_ids_one_hot[idx][token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd4ffa6f-c0dc-4013-ae17-e0a0d382810f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 103])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a0529-d58a-44c7-80c2-609b94af1a66",
   "metadata": {},
   "source": [
    "用`one-hot`来表示单词，是单词映射到向量的最简单的方法之一。`one-hot`向量的维度就是单词字典的大小。   \n",
    "这里单词字典的个数是103，那么向量维度就是103.\n",
    "\n",
    "**注意：** 这里的`one-hot`向量其实没有真正的语义含义的，没法表示出单词各属性的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01e38fae-fab0-423f-b121-11c1f905fa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30cb54b1-526c-4303-b606-80dc7da51030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids_one_hot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0323222f-907c-4cae-a717-cd64eb5b944c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(word_ids_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e7697-4782-4c1d-9dfd-4b9b04899e29",
   "metadata": {},
   "source": [
    "分词器重要的一点是：输入的是原始文本，输出是向量序列。   \n",
    "\n",
    "**注意：** 上面的**字符词元化**、**单词词元化**的分词示例，在实际应用中是不会使用这种分词方式的。我们一般会使用介于字符词元化和单词词元化之间的子词词元化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131da31c-9a93-41b6-8ba5-e46e2ca32c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
